# KoLa: Korean speech to LaTeX extraction Using small LM Modules

ğŸ“¢ 2025ë…„ 1í•™ê¸° [AIKU](https://github.com/AIKU-Official) í™œë™ìœ¼ë¡œ ì§„í–‰í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤
ğŸ‰ 2025ë…„ 1í•™ê¸° AIKU Conference ì—´ì‹¬íˆìƒ ìˆ˜ìƒ!

## ì†Œê°œ

Pipeline: KoLaëŠ” í•œêµ­ì–´ ìˆ˜í•™ ìŒì„±ì„ LaTeX ìˆ˜ì‹ìœ¼ë¡œ ì§ì ‘ ë³€í™˜í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ê°€ë³ê³  ëª¨ë“ˆí™”ëœ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤!
Dataset Generation: í•œêµ­ì–´ ìˆ˜í•™ ìŒì„±, í…ìŠ¤íŠ¸ ì „ì‚¬, ê·¸ë¦¬ê³  ì´ì— ëŒ€ì‘í•˜ëŠ” LaTeX ìˆ˜ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§„ 10ë§Œ ê°œ ê·œëª¨ì˜ ë³‘ë ¬ ë°ì´í„°ì…‹ì¸ KoTeX-100Kì™€ KoTeX-400Kë¥¼ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤!

## ë°©ë²•ë¡ 

KoLaëŠ” Whisper ê¸°ë°˜ì˜ ìŒì„± ì¸ì‹(ASR) ëª¨ë“ˆì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
ì´í›„, í…ìŠ¤íŠ¸ ê¸°ë°˜ Error Correctorì™€ LaTeX Translatorë¼ëŠ” ë‘ ê°œì˜ T5-base ê¸°ë°˜ ëª¨ë“ˆì´ ìˆœì°¨ì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.
ì´ ë‘ ëª¨ë“ˆì€ KoTeX-100Kì™€ KoTeX-400K ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµë©ë‹ˆë‹¤.
ì´ë¥¼ í†µí•´, ìŒì„± ì¸ì‹ ì˜¤ë¥˜ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë³´ì •í•˜ê³  LaTex Translation ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
(SOTAë˜í•œ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!!:) )

![KoLa Model Architecture](src/model_fig.jpg)


## ì˜ˆì‹œ ê²°ê³¼

![Results](src/experiment.jpg)


- í•œêµ­ì–´ ìŒì„±ì„ ë°›ê³ , ëŒ€ì‘ë˜ëŠ” LaTeXë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

- ì˜ˆì‹œ input: ì—ì´ì œê³± ë”í•˜ê¸° ë¹„ì œê³±
- ì˜ˆì‹œ output:
$$
\frac{a^2 + b^2}
$$

## íŒ€ì›

- [ê¹€ë¯¼ì¤€](ddomjun): build, train, test KoLa model pipeline code
- [ì „í˜œì„œ](doupari): data generation, data pre-/post-processing, evaluation on other LLM models
- [ê¹€íƒœê´€](TTKKWAN): build, train, test KoLa model pipeline code
- [ìœ¤ìŠ¹í˜„](xiseren): data generation, data pre-/post-processing
